{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NT-zgovR5fd"
      },
      "source": [
        "# VLLM Serve Demo on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKuOdJDRzeR"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIpiJ60fkIb2",
        "outputId": "3ef13b4b-5942-410e-ac19-384526edb472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vllm in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2025.11.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (6.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.0.8)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers<5,>=4.56.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.57.2)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.118.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.2)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.8.1)\n",
            "Requirement already satisfied: pydantic>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.12.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.11.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.11.3)\n",
            "Requirement already satisfied: llguidance<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.3.0)\n",
            "Requirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.11)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (5.6.3)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.25 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.1.25)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.20.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1.1.post7)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from vllm) (0.20.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.17.1)\n",
            "Requirement already satisfied: mistral_common>=1.8.5 in /usr/local/lib/python3.12/dist-packages (from mistral_common[image]>=1.8.5->vllm) (1.8.6)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n",
            "Requirement already satisfied: setuptools<81.0.0,>=77.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (80.9.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.12.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.2)\n",
            "Requirement already satisfied: depyf==0.20.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.20.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.2)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.12/dist-packages (from vllm) (1.1.1)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.16.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from vllm) (1.13.0)\n",
            "Requirement already satisfied: pybase64 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.4.2)\n",
            "Requirement already satisfied: cbor2 in /usr/local/lib/python3.12/dist-packages (from vllm) (5.7.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.12/dist-packages (from vllm) (1.3.7)\n",
            "Requirement already satisfied: openai-harmony>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.0.8)\n",
            "Requirement already satisfied: anthropic==0.71.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.71.0)\n",
            "Requirement already satisfied: model-hosting-container-standards<1.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.1.4)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.61.2)\n",
            "Requirement already satisfied: ray>=2.48.0 in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (2.52.1)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchaudio==2.9.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.24.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.24.0+cu126)\n",
            "Requirement already satisfied: xformers==0.0.33.post1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.0.33.post1)\n",
            "Requirement already satisfied: flashinfer-python==0.5.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.5.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->vllm) (0.7.3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm) (0.3.8)\n",
            "Requirement already satisfied: apache-tvm-ffi<0.2,>=0.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (0.1.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (8.2.1)\n",
            "Requirement already satisfied: nvidia-cudnn-frontend>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (1.16.0)\n",
            "Requirement already satisfied: nvidia-cutlass-dsl>=4.2.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (4.3.1)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (13.580.82)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (25.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.2->vllm) (0.9.0)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm) (0.3.3)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->vllm) (0.44.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm) (3.5.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.48.0)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.16)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.38.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (4.25.1)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2.10.6)\n",
            "Requirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0->vllm) (1.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm) (0.4.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2025.11.12)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.56.0->vllm) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.22.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.8.0)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.20.0)\n",
            "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.17.0)\n",
            "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->vllm) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (0.29.0)\n",
            "Requirement already satisfied: cuda-python>=12.8 in /usr/local/lib/python3.12/dist-packages (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm) (12.9.4)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm) (24.6.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->vllm) (1.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.22.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: cuda-bindings~=12.9.4 in /usr/local/lib/python3.12/dist-packages (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm) (12.9.4)\n",
            "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.7.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.46.0)\n",
            "Requirement already satisfied: fastar>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.8.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings~=12.9.4->cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.2->vllm) (1.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install vllm bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3LqsP8cSDLm"
      },
      "source": [
        "## Install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEJL-zAwkRPU",
        "outputId": "48d84168-975b-41df-d815-f7a4b3ebc8cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-01 14:24:26--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 75.2.60.68, 35.71.179.82, 13.248.244.96, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|75.2.60.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10980950 (10M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-v3-stable-linux-amd64.tgz.1’\n",
            "\n",
            "ngrok-v3-stable-lin 100%[===================>]  10.47M  4.46MB/s    in 2.3s    \n",
            "\n",
            "2025-12-01 14:24:30 (4.46 MB/s) - ‘ngrok-v3-stable-linux-amd64.tgz.1’ saved [10980950/10980950]\n",
            "\n",
            "ngrok\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!sudo tar xvzf ./ngrok-v3-stable-linux-amd64.tgz -C /usr/local/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM_vug-3wapb",
        "outputId": "b42cb985-5dfe-41de-a024-329ad0543865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!curl -sSL https://ngrok-agent.s3.amazonaws.com/ngrok.asc \\\n",
        "  | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null \\\n",
        "  && echo \"deb https://ngrok-agent.s3.amazonaws.com bookworm main\" \\\n",
        "  | sudo tee /etc/apt/sources.list.d/ngrok.list \\\n",
        "  && sudo apt update \\\n",
        "  && sudo apt install ngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kmEKpO3SFz2"
      },
      "source": [
        "## Add Ngrok access token\n",
        "**Remember to set the NGROK_TOKEN in Google Colab's secrets page**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqCz-uYDkTfg",
        "outputId": "ff6da31c-7407-46f0-f6fd-c7a5e87b13cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "ngrok_token = userdata.get('NGROK_TOKEN')\n",
        "\n",
        "!ngrok config add-authtoken \"$ngrok_token\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTEMBgckSzIS"
      },
      "source": [
        "## Run Ngrok and pass port forward port 8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mZ0sLPOxliuQ"
      },
      "outputs": [],
      "source": [
        "!nohup ngrok http 8000 > ngrok.log 2>&1 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MZZ7VJXlnMl",
        "outputId": "77f821a2-8969-4de7-a8e1-f33165cd9971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-01 15:45:19.281250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764603919.301223   21258 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764603919.307289   21258 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764603919.323206   21258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764603919.323239   21258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764603919.323243   21258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764603919.323246   21258 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-01 15:45:19.327906: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 12-01 15:45:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:45:31 [api_server.py:1977] vLLM API server version 0.11.2\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:45:31 [utils.py:253] non-default args: {'model_tag': 'BigJuicyData/coder-final', 'model': 'BigJuicyData/coder-final', 'trust_remote_code': True, 'dtype': 'float16', 'max_model_len': 6000, 'quantization': 'bitsandbytes', 'enforce_eager': True, 'load_format': 'bitsandbytes', 'max_num_seqs': 8}\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:45:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m WARNING 12-01 15:45:32 [model.py:1971] Casting torch.bfloat16 to torch.float16.\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:45:32 [model.py:1745] Using max model len 6000\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:45:34 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:45:34 [vllm.py:500] Cudagraph is disabled under eager mode\n",
            "2025-12-01 15:45:43.999214: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764603944.019796   21387 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764603944.025987   21387 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764603944.042765   21387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764603944.042798   21387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764603944.042803   21387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764603944.042809   21387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:45:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='BigJuicyData/coder-final', speculative_config=None, tokenizer='BigJuicyData/coder-final', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=6000, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=BigJuicyData/coder-final, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': None, 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 0, 'local_cache_dir': None}\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m ERROR 12-01 15:45:52 [fa_utils.py:64] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:45:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://172.28.0.12:59367 backend=nccl\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:45:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:45:54 [gpu_model_runner.py:3259] Starting to load model BigJuicyData/coder-final...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:45:57 [cuda.py:418] Valid backends: ['FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:45:57 [cuda.py:427] Using FLASHINFER backend.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:45:57 [bitsandbytes_loader.py:791] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "Loading safetensors checkpoint shards: 100% 6/6 [02:18<00:00, 23.02s/it]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:48:18 [gpu_model_runner.py:3338] Model loading took 9.9038 GiB memory and 142.632923 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:48:43 [gpu_worker.py:359] Available KV cache memory: 2.79 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:48:44 [kv_cache_utils.py:1229] GPU KV cache size: 18,304 tokens\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:48:44 [kv_cache_utils.py:1234] Maximum concurrency for 6,000 tokens per request: 3.05x\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:48:44 [kernel_warmup.py:65] Warming up FlashInfer attention.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:48:47 [core.py:250] init engine (profile, create kv cache, warmup model) took 28.89 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=21387)\u001b[0;0m INFO 12-01 15:48:49 [vllm.py:500] Cudagraph is disabled under eager mode\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards - decorators.py:76: [PING] Framework handler registered: ping\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards:[PING] Framework handler registered: ping\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.transforms.base_factory - base_factory.py:90: [INJECT_ADAPTER_ID] Transform decorator applied to: invocations\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.transforms.base_factory:[INJECT_ADAPTER_ID] Transform decorator applied to: invocations\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.transforms.base_factory - base_factory.py:115: [INJECT_ADAPTER_ID] Registered transform handler for invocations\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.transforms.base_factory:[INJECT_ADAPTER_ID] Registered transform handler for invocations\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.transforms.base_factory - base_factory.py:90: [STATEFUL_SESSION_MANAGER] Transform decorator applied to: decorated_func\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.transforms.base_factory:[STATEFUL_SESSION_MANAGER] Transform decorator applied to: decorated_func\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.transforms.base_factory - base_factory.py:115: [STATEFUL_SESSION_MANAGER] Registered transform handler for decorated_func\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.transforms.base_factory:[STATEFUL_SESSION_MANAGER] Registered transform handler for decorated_func\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards - decorators.py:76: [INVOKE] Framework handler registered: decorated_func\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards:[INVOKE] Framework handler registered: decorated_func\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards - __init__.py:127: Starting SageMaker bootstrap process\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards:Starting SageMaker bootstrap process\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards - registry.py:109: [REGISTRY] Middleware resolution and registration complete\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards:[REGISTRY] Middleware resolution and registration complete\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards - core.py:100: [MIDDLEWARE_LOADER] Middleware stack rebuilt successfully\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards:[MIDDLEWARE_LOADER] Middleware stack rebuilt successfully\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards - core.py:102: [MIDDLEWARE_LOADER] Processed 3 middlewares\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards:[MIDDLEWARE_LOADER] Processed 3 middlewares\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [WARNING] model_hosting_container_standards.common.custom_code_ref_resolver.function_loader - function_loader.py:73: Failed to load function from spec 'model:custom_sagemaker_invocation_handler': HandlerFileNotFoundError: File '/opt/ml/model/model.py' not found in search paths: ['/opt/ml/model/']\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m WARNING:model_hosting_container_standards.common.custom_code_ref_resolver.function_loader:Failed to load function from spec 'model:custom_sagemaker_invocation_handler': HandlerFileNotFoundError: File '/opt/ml/model/model.py' not found in search paths: ['/opt/ml/model/']\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [WARNING] model_hosting_container_standards.common.custom_code_ref_resolver.function_loader - function_loader.py:73: Failed to load function from spec 'model:custom_sagemaker_ping_handler': HandlerFileNotFoundError: File '/opt/ml/model/model.py' not found in search paths: ['/opt/ml/model/']\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m WARNING:model_hosting_container_standards.common.custom_code_ref_resolver.function_loader:Failed to load function from spec 'model:custom_sagemaker_ping_handler': HandlerFileNotFoundError: File '/opt/ml/model/model.py' not found in search paths: ['/opt/ml/model/']\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.sagemaker.sagemaker_router - sagemaker_router.py:93: Creating SageMaker router with unified route resolver\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.sagemaker.sagemaker_router:Creating SageMaker router with unified route resolver\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.fastapi.routing - routing.py:172: Creating router with prefix='', tags=['sagemaker']\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.fastapi.routing:Creating router with prefix='', tags=['sagemaker']\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.fastapi.routing - routing.py:110: Mounting 2 handlers to router\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.fastapi.routing:Mounting 2 handlers to router\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.fastapi.routing - routing.py:184: Router created with 0 routes\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.fastapi.routing:Router created with 0 routes\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.sagemaker.sagemaker_router - sagemaker_router.py:101: SageMaker router created successfully with 0 routes\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.sagemaker.sagemaker_router:SageMaker router created successfully with 0 routes\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.fastapi.routing - routing.py:287: Including router with conflict detection\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.fastapi.routing:Including router with conflict detection\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards.common.fastapi.routing - routing.py:305: Successfully included router with 0 routes\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards.common.fastapi.routing:Successfully included router with 0 routes\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m [INFO] model_hosting_container_standards - __init__.py:139: SageMaker bootstrap completed successfully\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO:model_hosting_container_standards:SageMaker bootstrap completed successfully\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:50 [api_server.py:1725] Supported tasks: ['generate']\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [api_server.py:2052] Starting vLLM API server 0 on http://0.0.0.0:8000\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:38] Available routes are:\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /openapi.json, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /docs, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /docs/oauth2-redirect, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /redoc, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /health, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /load, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /tokenize, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /detokenize, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/models, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /version, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/responses, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/responses/{response_id}, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/responses/{response_id}/cancel, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/messages, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/chat/completions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/completions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/embeddings, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /pooling, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /classify, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /score, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/score, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/audio/transcriptions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/audio/translations, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /rerank, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v1/rerank, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /v2/rerank, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /scale_elastic_ep, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /is_scaling_elastic_ep, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /inference/v1/generate, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /ping, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /ping, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /invocations, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m INFO 12-01 15:48:52 [launcher.py:46] Route: /metrics, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m \u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m21258\u001b[0m]\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m \u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[1;36m(APIServer pid=21258)\u001b[0;0m \u001b[32mINFO\u001b[0m:     Application startup complete.\n"
          ]
        }
      ],
      "source": [
        "!vllm serve BigJuicyData/Anni \\\n",
        "  --quantization bitsandbytes \\\n",
        "  --load-format bitsandbytes \\\n",
        "  --trust-remote-code \\\n",
        "  --max-model-len 6000 \\\n",
        "  --dtype float16 \\\n",
        "  --gpu-memory-utilization 0.90 \\\n",
        "  --enforce-eager \\\n",
        "  --max-num-seqs 8"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
